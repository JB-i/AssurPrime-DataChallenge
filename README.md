# ENS Data Challenge 2025 â€“ AssurPrime

This repository contains my solution to the **ENS Data Challenge 2025 (AssurPrime)**.  
The goal of the challenge was to **predict insurance premiums** using anonymized client and contract data.

## Project Overview
- Ranked **8th in the global leaderboard**.
- Implemented end-to-end workflow in Python (data cleaning, feature engineering, model training, evaluation).
- Final models: **XGBoost + HistGradientBoosting with Optuna hyperparameter tuning and SHAP feature analysis**.

## Repository Structure

```
AssurPrime-DataChallenge/
â”‚
â”œâ”€â”€ notebooks/ # Jupyter notebooks
â”‚ â”œâ”€â”€ 01_data_exploration.ipynb
â”‚ â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚ â”œâ”€â”€ 03_modeling_optuna_xgb.ipynb
â”‚ â””â”€â”€ 04_results_visualization.ipynb
â”‚
â”œâ”€â”€ src/ # Reusable Python scripts
â”‚ â”œâ”€â”€ preprocessing.py
â”‚ â”œâ”€â”€ modeling.py
â”‚ â””â”€â”€ evaluation.py
â”‚
â”œâ”€â”€ results/ # Figures and outputs
â”‚ â”œâ”€â”€ shap_summary.png
â”‚ â”œâ”€â”€ feature_importance.png
â”‚ â””â”€â”€ performance_table.csv
â”‚
â””â”€â”€ requirements.txt # Python dependencies
```


## âš™ï¸ Methods
- **Data preprocessing:** handled missing values, categorical encoding, log transformations.  
- **Feature selection:** SHAP values and domain heuristics.  
- **Modeling:** XGBoost, HistGradientBoostingRegressor, stacking ensemble.  
- **Optimization:** Optuna for Bayesian hyperparameter search.  

## ğŸ“Š Results
- Ranked **8th overall** in the official leaderboard.  
- Achieved a significant RMSE improvement compared to baseline linear regression.  
- SHAP visualizations highlight the most predictive features.  

## ğŸ”§ Installation
To run the project locally:

```bash
git clone https://github.com/JB-i/AssurPrime-DataChallenge.git
cd AssurPrime-DataChallenge
pip install -r requirements.txt
