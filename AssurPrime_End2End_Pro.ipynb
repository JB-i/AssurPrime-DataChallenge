{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ef0ffe8",
   "metadata": {},
   "source": [
    "# ENS Data Challenge 2025 â€“ AssurPrime\n",
    "\n",
    "This notebook implements an end-to-end pipeline to predict the insurance charge **CHARGE** from anonymized client and contract data.\n",
    "\n",
    "**Workflow**\n",
    "1. Load raw data and set up repository paths.\n",
    "2. Preprocess and encode features; keep test IDs for the final submission.\n",
    "3. Deterministic split: **1%** (development/tuning) and **99%** (holdout validation).\n",
    "4. SHAP-based mixed feature ranking (separate models for FREQ and CM).\n",
    "5. Hyperparameter tuning with Optuna for model and post-processing parameters.\n",
    "6. Final training on selected features and evaluation on the 99% holdout.\n",
    "7. Submission file generation for the challenge platform.\n",
    "\n",
    "Expected repository structure:\n",
    "```\n",
    "data/\n",
    "  raw/         # challenge CSVs (download separately; not versioned)\n",
    "  processed/   # intermediate artifacts (generated locally)\n",
    "models/        # saved params/models (optional)\n",
    "results/       # figures and submission files\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70da8164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Explainability\n",
    "import shap\n",
    "\n",
    "# Repository directories (relative paths)\n",
    "RAW_DIR = \"data/raw\"\n",
    "PROC_DIR = \"data/processed\"\n",
    "MODELS_DIR = \"models\"\n",
    "RESULTS_DIR = \"results\"\n",
    "\n",
    "os.makedirs(PROC_DIR, exist_ok=True)\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Raw challenge CSVs (place them manually in data/raw/)\n",
    "PATH_X_RAW   = f\"{RAW_DIR}/train_input_Z61KlZo.csv\"\n",
    "PATH_Y_RAW   = f\"{RAW_DIR}/train_output_DzPxaPY.csv\"\n",
    "PATH_TEST_RAW= f\"{RAW_DIR}/test_input_5qJzHrr.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6d7313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw datasets\n",
    "X_raw    = pd.read_csv(PATH_X_RAW)\n",
    "y_raw    = pd.read_csv(PATH_Y_RAW)\n",
    "test_raw = pd.read_csv(PATH_TEST_RAW)\n",
    "\n",
    "print(\"Loaded raw data.\")\n",
    "print(\"X_raw:\", X_raw.shape, \"| y_raw:\", y_raw.shape, \"| test_raw:\", test_raw.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41912a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test IDs/ANNEE_ASSURANCE for submission\n",
    "test_ids = test_raw[[\"ID\", \"ANNEE_ASSURANCE\"]].copy()\n",
    "test_ids.to_csv(f\"{PROC_DIR}/test_ids.csv\", index=False)\n",
    "\n",
    "# Drop ID/ANNEE from training/test before encoding\n",
    "for df in (X_raw, test_raw):\n",
    "    for col in (\"ID\", \"ANNEE_ASSURANCE\"):\n",
    "        if col in df.columns:\n",
    "            df.drop(columns=col, inplace=True)\n",
    "\n",
    "# Encode categorical columns and impute numeric NaNs with median\n",
    "def encode_impute(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype == \"object\":\n",
    "            df[c] = df[c].astype(\"category\").cat.codes\n",
    "    df = df.fillna(df.median(numeric_only=True))\n",
    "    return df\n",
    "\n",
    "X          = encode_impute(X_raw)\n",
    "X_test_enc = encode_impute(test_raw)\n",
    "y          = y_raw.copy()\n",
    "\n",
    "# Persist processed artifacts (optional, for reproducibility)\n",
    "X.to_csv(f\"{PROC_DIR}/train_input_encoded.csv\", index=False)\n",
    "y.to_csv(f\"{PROC_DIR}/train_output_encoded.csv\", index=False)\n",
    "X_test_enc.to_csv(f\"{PROC_DIR}/test_input_encoded.csv\", index=False)\n",
    "\n",
    "print(\"Preprocessing complete.\")\n",
    "print(\"X:\", X.shape, \"| X_test_enc:\", X_test_enc.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4c5b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deterministic 1% / 99% split by rows\n",
    "rng = 42\n",
    "X_01 = X.sample(frac=0.01, random_state=rng)\n",
    "y_01 = y.loc[X_01.index].copy()\n",
    "\n",
    "X_99 = X.drop(X_01.index)\n",
    "y_99 = y.drop(X_01.index)\n",
    "\n",
    "# Save splits (optional)\n",
    "X_01.to_csv(f\"{PROC_DIR}/train_input_reduit_0_01.csv\", index=False)\n",
    "y_01.to_csv(f\"{PROC_DIR}/train_output_reduit_0_01.csv\", index=False)\n",
    "X_99.to_csv(f\"{PROC_DIR}/train_input_reduit_0_99.csv\", index=False)\n",
    "y_99.to_csv(f\"{PROC_DIR}/train_output_reduit_0_99.csv\", index=False)\n",
    "\n",
    "print(\"Split complete.\")\n",
    "print(\"1%:\", X_01.shape, \"| 99%:\", X_99.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874c768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base learner for SHAP estimation\n",
    "xgb_base = dict(\n",
    "    objective=\"reg:squarederror\",\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# SHAP on FREQ (1%)\n",
    "xgb_freq = xgb.XGBRegressor(max_depth=6, **xgb_base)\n",
    "xgb_freq.fit(X_01, y_01[\"FREQ\"])\n",
    "expl_freq = shap.Explainer(xgb_freq, X_01)\n",
    "shap_freq = pd.DataFrame(expl_freq(X_01).values, columns=X_01.columns).abs().mean()\n",
    "\n",
    "# SHAP on CM (1%)\n",
    "xgb_cm = xgb.XGBRegressor(max_depth=6, **xgb_base)\n",
    "xgb_cm.fit(X_01, y_01[\"CM\"])\n",
    "expl_cm = shap.Explainer(xgb_cm, X_01)\n",
    "shap_cm = pd.DataFrame(expl_cm(X_01).values, columns=X_01.columns).abs().mean()\n",
    "\n",
    "# Mixing weight and number of features (use your tuned values if known)\n",
    "W_FREQ = 0.2807980997051884\n",
    "HEAD_N = 10\n",
    "\n",
    "combined_shap = (W_FREQ * shap_freq + (1 - W_FREQ) * shap_cm).sort_values(ascending=False)\n",
    "top_vars = combined_shap.head(HEAD_N).index.tolist()\n",
    "\n",
    "print(\"Selected features:\", top_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99af9004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "# Holdout target (99%)\n",
    "annee_assurance_99 = y_99[\"ANNEE_ASSURANCE\"].to_numpy()\n",
    "charge_real_99 = (y_99[\"FREQ\"] * y_99[\"CM\"] * y_99[\"ANNEE_ASSURANCE\"]).to_numpy()\n",
    "\n",
    "# Search space\n",
    "PARAM_RANGES = {\n",
    "    \"w_freq\":        (0.01, 0.4),\n",
    "    \"head_n\":        (6, 20),\n",
    "    \"max_depth_freq\": (2, 10),\n",
    "    \"lr_freq\":       (0.01, 0.12),\n",
    "    \"subsample_freq\": (0.6, 1.0),\n",
    "    \"colsample_freq\": (0.6, 1.0),\n",
    "    \"lr_cm\":         (0.02, 0.1),\n",
    "    \"max_depth_cm\":  (2, 10),\n",
    "    \"a\":             (0.005, 0.25),\n",
    "    \"b\":             (1.3, 2.6),\n",
    "    \"c\":             (9, 17),\n",
    "    \"d\":             (0.15, 0.45),\n",
    "    \"log_base\":      (1.2, 3.2),\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # Sample parameters\n",
    "    p = {}\n",
    "    for k, (lo, hi) in PARAM_RANGES.items():\n",
    "        if isinstance(lo, int) and isinstance(hi, int):\n",
    "            p[k] = trial.suggest_int(k, lo, hi)\n",
    "        else:\n",
    "            p[k] = trial.suggest_float(k, lo, hi)\n",
    "\n",
    "    # Mixed SHAP feature selection\n",
    "    combined = (p[\"w_freq\"] * shap_freq + (1 - p[\"w_freq\"]) * shap_cm).sort_values(ascending=False)\n",
    "    top = combined.head(p[\"head_n\"]).index.tolist()\n",
    "\n",
    "    X_tr = X_01[top]\n",
    "    X_va = X_99[top]\n",
    "\n",
    "    # Models\n",
    "    freq_model = xgb.XGBRegressor(\n",
    "        max_depth=p[\"max_depth_freq\"], n_estimators=300, learning_rate=p[\"lr_freq\"],\n",
    "        subsample=p[\"subsample_freq\"], colsample_bytree=p[\"colsample_freq\"],\n",
    "        objective=\"reg:squarederror\", n_jobs=-1, random_state=42\n",
    "    )\n",
    "    freq_model.fit(X_tr, y_01[\"FREQ\"])\n",
    "\n",
    "    cm_model = HistGradientBoostingRegressor(\n",
    "        max_iter=300, learning_rate=p[\"lr_cm\"], max_depth=p[\"max_depth_cm\"], random_state=42\n",
    "    )\n",
    "    cm_model.fit(X_tr, y_01[\"CM\"])\n",
    "\n",
    "    # Predictions on 99%\n",
    "    freq_pred = freq_model.predict(X_va)\n",
    "    cm_pred   = cm_model.predict(X_va)\n",
    "\n",
    "    # Charge recomposition (with numeric safeguards)\n",
    "    freq_term = np.power(np.abs(freq_pred), p[\"a\"])\n",
    "    log_cm = np.log(np.clip(np.abs(cm_pred), 1e-8, None)) / np.log(max(p[\"log_base\"], 1e-8))\n",
    "    base_cm = np.clip(log_cm + p[\"c\"], 1e-8, None)\n",
    "    cm_term = np.power(base_cm, p[\"b\"])\n",
    "    ann_term = np.power(np.log1p(np.clip(annee_assurance_99, 0.0, None)), p[\"d\"])\n",
    "\n",
    "    charge_pred = freq_term * cm_term * ann_term\n",
    "    if np.isnan(charge_pred).any():\n",
    "        return float(\"inf\")\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(charge_real_99, charge_pred))\n",
    "    return rmse\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=10)  # Here only 10 trials but we let it run for days\n",
    "\n",
    "print(\"Best params:\", study.best_params)\n",
    "print(\"Best RMSE (99% holdout):\", study.best_value)\n",
    "\n",
    "# Save best params\n",
    "with open(f\"{MODELS_DIR}/best_params.json\", \"w\") as f:\n",
    "    json.dump(study.best_params, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7716ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best parameters\n",
    "with open(f\"{MODELS_DIR}/best_params.json\") as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "# Recompute mixed SHAP ranking with stored w_freq/head_n\n",
    "combined_final = (params[\"w_freq\"] * shap_freq + (1 - params[\"w_freq\"]) * shap_cm).sort_values(ascending=False)\n",
    "top_vars_final = combined_final.head(params[\"head_n\"]).index.tolist()\n",
    "\n",
    "# Train on 1% with final params and validate on 99%\n",
    "X_tr_best = X_01[top_vars_final]\n",
    "X_va_best = X_99[top_vars_final]\n",
    "\n",
    "freq_model = xgb.XGBRegressor(\n",
    "    max_depth=params[\"max_depth_freq\"], n_estimators=300, learning_rate=params[\"lr_freq\"],\n",
    "    subsample=params[\"subsample_freq\"], colsample_bytree=params[\"colsample_freq\"],\n",
    "    objective=\"reg:squarederror\", n_jobs=-1, random_state=42\n",
    ")\n",
    "freq_model.fit(X_tr_best, y_01[\"FREQ\"])\n",
    "\n",
    "cm_model = HistGradientBoostingRegressor(\n",
    "    max_iter=300, learning_rate=params[\"lr_cm\"], max_depth=params[\"max_depth_cm\"], random_state=42\n",
    ")\n",
    "cm_model.fit(X_tr_best, y_01[\"CM\"])\n",
    "\n",
    "# Validation on 99%\n",
    "freq_pred = freq_model.predict(X_va_best)\n",
    "cm_pred   = cm_model.predict(X_va_best)\n",
    "annee_99  = y_99[\"ANNEE_ASSURANCE\"].to_numpy()\n",
    "\n",
    "freq_term = np.power(np.abs(freq_pred), params[\"a\"])\n",
    "log_cm = np.log(np.clip(np.abs(cm_pred), 1e-8, None)) / np.log(max(params[\"log_base\"], 1e-8))\n",
    "base_cm = np.clip(log_cm + params[\"c\"], 1e-8, None)\n",
    "cm_term = np.power(base_cm, params[\"b\"])\n",
    "ann_term = np.power(np.log1p(np.clip(annee_99, 0.0, None)), params[\"d\"])\n",
    "\n",
    "charge_pred = freq_term * cm_term * ann_term\n",
    "charge_real = (y_99[\"FREQ\"] * y_99[\"CM\"] * y_99[\"ANNEE_ASSURANCE\"]).to_numpy()\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(charge_real, charge_pred))\n",
    "print(f\"RMSE on 99% holdout: {rmse:.6f}\")\n",
    "\n",
    "# Fit final models on the full training set (for submission)\n",
    "X_full_top = X[top_vars_final]\n",
    "freq_model.fit(X_full_top, y[\"FREQ\"])\n",
    "cm_model.fit(X_full_top, y[\"CM\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb71cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare submission features\n",
    "X_submit = pd.read_csv(f\"{PROC_DIR}/test_input_encoded.csv\")\n",
    "ids_df   = pd.read_csv(f\"{PROC_DIR}/test_ids.csv\")\n",
    "\n",
    "X_submit_best = X_submit[top_vars_final]\n",
    "\n",
    "# Predict on test\n",
    "freq_submit = freq_model.predict(X_submit_best)\n",
    "cm_submit   = cm_model.predict(X_submit_best)\n",
    "annee_submit= ids_df[\"ANNEE_ASSURANCE\"].to_numpy()\n",
    "\n",
    "# Recompose CHARGE with numeric safeguards\n",
    "freq_term_s = np.power(np.abs(freq_submit), params[\"a\"])\n",
    "log_cm_s = np.log(np.clip(np.abs(cm_submit), 1e-8, None)) / np.log(max(params[\"log_base\"], 1e-8))\n",
    "base_cm_s = np.clip(log_cm_s + params[\"c\"], 1e-8, None)\n",
    "cm_term_s = np.power(base_cm_s, params[\"b\"])\n",
    "ann_term_s= np.power(np.log1p(np.clip(annee_submit, 0.0, None)), params[\"d\"])\n",
    "\n",
    "charge_submit = freq_term_s * cm_term_s * ann_term_s\n",
    "\n",
    "# Build submission\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": ids_df[\"ID\"],\n",
    "    \"FREQ\": freq_submit,\n",
    "    \"CM\": cm_submit,\n",
    "    \"ANNEE_ASSURANCE\": annee_submit,\n",
    "    \"CHARGE\": charge_submit\n",
    "})\n",
    "submission.to_csv(f\"{RESULTS_DIR}/submission.csv\", index=False)\n",
    "print(\"Submission saved at:\", f\"{RESULTS_DIR}/submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
